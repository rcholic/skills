"""
Soul Memory v3.1 - Cantonese (å»£æ±è©±) Grammar Branch Module
å»£æ±è©±èªæ³•åˆ†æ”¯ - èªæ°£è©èˆ‡èªå¢ƒæ˜ å°„ç³»çµ±

Version: 3.1.0
Author: Li Si (ææ–¯)
"""

import re
from enum import Enum
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field


class ToneIntensity(Enum):
    """èªæ°£å¼·åº¦ç­‰ç´š"""
    LIGHT = "è¼•å¾®"      # ç¨‹åº¦ 1
    MEDIUM = "ä¸­ç­‰"    # ç¨‹åº¦ 2
    STRONG = "å¼·çƒˆ"    # ç¨‹åº¦ 3


class ContextType(Enum):
    """èªå¢ƒé¡å‹"""
    CASUAL = "é–’èŠ"      # è¼•é¬†å°è©±
    FORMAL = "æ­£å¼"      # æŠ€è¡“/æ­£å¼è¨è«–
    HUMOR = "å¹½é»˜"       # è¼•é¬†å¹½é»˜
    CONCESSION = "è®“æ­¥"  # è®“æ­¥èªæ°£
    EMPHASIS = "å¼·èª¿"    # å¼·èª¿èªæ°£


@dataclass
class CantoneseExpression:
    """å»£æ±è©±è¡¨é”å–®å…ƒ"""
    phrase: str
    tone_intensity: ToneIntensity
    context_types: List[ContextType]
    examples: List[str]
    tags: List[str]
    frequency: int = 0  # ä½¿ç”¨é »ç‡çµ±è¨ˆ


@dataclass
class CantoneseAnalysisResult:
    """ç²µèªåˆ†æçµæœ"""
    is_cantonese: bool
    confidence: float
    detected_particles: List[str]
    suggested_context: ContextType
    suggested_intensity: ToneIntensity
    tone_analysis: Dict[str, any] = field(default_factory=dict)


class CantoneseSyntaxBranch:
    """
    å»£æ±è©±èªæ³•åˆ†æ”¯æ ¸å¿ƒé¡åˆ¥
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†èªæ°£è©åŠå…¶ç¨‹åº¦åˆ†ç´š
    2. èªå¢ƒæ˜ å°„èˆ‡è‡ªå‹•é¸æ“‡
    3. ç²µèªæª¢æ¸¬èˆ‡åˆ†æ
    4. å‹•æ…‹è¡¨é”å»ºè­°
    """
    
    VERSION = "3.1.0"
    
    def __init__(self):
        # èªæ°£è©åˆ†é¡
        self.tone_particles: Dict[ToneIntensity, List[CantoneseExpression]] = {
            ToneIntensity.LIGHT: [],
            ToneIntensity.MEDIUM: [],
            ToneIntensity.STRONG: []
        }
        
        # èªå¢ƒæ˜ å°„
        self.context_mappings: Dict[ContextType, List[str]] = {}
        
        # ç”¨æˆ¶åå¥½è¨˜æ†¶
        self.user_preferences: Dict[str, List[str]] = {}
        
        # å­¸ç¿’åˆ°çš„è¡¨é”æ¨¡å¼
        self.learned_patterns: List[Dict] = []
        
        # åˆå§‹åŒ–é è¨­æ•¸æ“š
        self._init_default_data()
    
    def _init_default_data(self):
        """åˆå§‹åŒ–é è¨­å»£æ±è©±æ•¸æ“š"""
        # ç¨‹åº¦ 1ï¼šè¼•å¾®
        self.tone_particles[ToneIntensity.LIGHT] = [
            CantoneseExpression("æ¶", ToneIntensity.LIGHT, [ContextType.CASUAL, ContextType.EMPHASIS], 
                              ["ä¿‚æ¶", "å¥½æ¶", "æ˜æ¶"], ["èªæ°£è©", "è¼•å¾®", "è‚¯å®š"]),
            CantoneseExpression("å•¦", ToneIntensity.LIGHT, [ContextType.CASUAL, ContextType.CONCESSION],
                              ["å¥½å•¦", "ç®—å•¦", "å¤ å•¦"], ["èªæ°£è©", "è¼•å¾®", "è®“æ­¥"]),
            CantoneseExpression("å›‰", ToneIntensity.LIGHT, [ContextType.CASUAL, ContextType.EMPHASIS],
                              ["ä¿‚å›‰", "å¥½å›‰", "å¾—å›‰"], ["èªæ°£è©", "è¼•å¾®", "èªåŒ"]),
            CantoneseExpression("å–", ToneIntensity.LIGHT, [ContextType.CASUAL],
                              ["ä¿‚å–", "å“¦å–"], ["èªæ°£è©", "è¼•å¾®", "é†’æ‚Ÿ"]),
            CantoneseExpression("å˜…", ToneIntensity.LIGHT, [ContextType.CASUAL],
                              ["ä¿‚å˜…", "å¥½å˜…", "å¾—å˜…"], ["èªæ°£è©", "è¼•å¾®", "è‚¯å®š"]),
        ]
        
        # ç¨‹åº¦ 2ï¼šä¸­ç­‰
        self.tone_particles[ToneIntensity.MEDIUM] = [
            CantoneseExpression("çœŸä¿‚...å•¦", ToneIntensity.MEDIUM, [ContextType.EMPHASIS, ContextType.CASUAL],
                              ["çœŸä¿‚å‹æ¶å•¦", "çœŸä¿‚çŠ€åˆ©å•¦"], ["èªæ°£è©", "ä¸­ç­‰", "å¼·èª¿"]),
            CantoneseExpression("éƒ½...æ¶", ToneIntensity.MEDIUM, [ContextType.CASUAL, ContextType.EMPHASIS],
                              ["æˆ‘éƒ½ä¿‚æ¶", "ä½ éƒ½è­˜æ¶"], ["èªæ°£è©", "ä¸­ç­‰", "åŒ…å«"]),
            CantoneseExpression("å¥½å•¦", ToneIntensity.MEDIUM, [ContextType.CONCESSION, ContextType.CASUAL],
                              ["å¥½å•¦å¥½å•¦", "å¥½å•¦å•¦"], ["èªæ°£è©", "ä¸­ç­‰", "è®“æ­¥"]),
            CantoneseExpression("ç®—å•¦", ToneIntensity.MEDIUM, [ContextType.CONCESSION],
                              ["ç®—å•¦ç®—å•¦", "å””ç·Šè¦ç®—å•¦"], ["èªæ°£è©", "ä¸­ç­‰", "æ”¾æ£„"]),
            CantoneseExpression("å’å•¦", ToneIntensity.MEDIUM, [ContextType.CONCESSION, ContextType.CASUAL],
                              ["å’å•¦å’å•¦", "ä¿‚å’å•¦"], ["èªæ°£è©", "ä¸­ç­‰", "è®“æ­¥"]),
        ]
        
        # ç¨‹åº¦ 3ï¼šå¼·çƒˆ
        self.tone_particles[ToneIntensity.STRONG] = [
            CantoneseExpression("å¥½çŠ€åˆ©æ¶ï¼", ToneIntensity.STRONG, [ContextType.HUMOR, ContextType.EMPHASIS],
                              ["æ‚Ÿé£¯å¥½çŠ€åˆ©æ¶ï¼", "å‘¢æ‹›å¥½çŠ€åˆ©æ¶ï¼"], ["èªæ°£è©", "å¼·çƒˆ", "è®šå˜†"]),
            CantoneseExpression("ä¿‚æ™’æ¶ï¼", ToneIntensity.STRONG, [ContextType.EMPHASIS, ContextType.HUMOR],
                              ["ä¿‚æ™’æ¶ï¼", "çœŸä¿‚ä¿‚æ™’æ¶ï¼"], ["èªæ°£è©", "å¼·çƒˆ", "å®Œå…¨è‚¯å®š"]),
            CantoneseExpression("ææ‚æ™’å•¦ï¼", ToneIntensity.STRONG, [ContextType.HUMOR, ContextType.CONCESSION],
                              ["ææ‚æ™’å•¦ï¼", "å®Œæˆæ™’å•¦ï¼"], ["èªæ°£è©", "å¼·çƒˆ", "å®Œæˆ"]),
            CantoneseExpression("çŠ€åˆ©åˆ°çˆ†ï¼", ToneIntensity.STRONG, [ContextType.HUMOR, ContextType.EMPHASIS],
                              ["çŠ€åˆ©åˆ°çˆ†ï¼", "å‹åˆ°çˆ†ï¼"], ["èªæ°£è©", "å¼·çƒˆ", "æ¥µè‡´"]),
            CantoneseExpression("å‹åˆ°ç™²ï¼", ToneIntensity.STRONG, [ContextType.HUMOR],
                              ["å‹åˆ°ç™²ï¼", "çŠ€åˆ©åˆ°ç™²ï¼"], ["èªæ°£è©", "å¼·çƒˆ", "èª‡å¼µ"]),
        ]
        
        # èªå¢ƒæ˜ å°„
        self.context_mappings = {
            ContextType.CASUAL: ["æ¶", "å•¦", "å›‰", "çŠ€åˆ©", "å¥½", "å¾—", "å˜…", "å–"],
            ContextType.FORMAL: ["ä¿‚å’", "æ‰€ä»¥", "å’æ¨£", "å³ä¿‚", "å…¶å¯¦", "åŸºæœ¬ä¸Š"],
            ContextType.HUMOR: ["è¡°é¬¼", "æ‰®æ™’å˜¢", "çŠ€åˆ©åˆ°çˆ†", "ææ‚æ™’", "çœŸä¿‚é›¢è­œ", "å‹åˆ°ç™²"],
            ContextType.CONCESSION: ["å¥½å•¦", "ç®—å•¦", "å’å•¦", "ç„¡è¬‚å•¦", "ç½·å°±"],
            ContextType.EMPHASIS: ["çœŸä¿‚", "ç¢ºå¯¦", "è€å¯¦è¬›", "è€å¯¦èªª", "è¬›çœŸ"]
        }
    
    def detect_cantonese(self, text: str) -> Tuple[bool, float]:
        """
        æª¢æ¸¬æ–‡æœ¬æ˜¯å¦åŒ…å«å»£æ±è©±å…ƒç´ 
        
        Returns:
            (æ˜¯å¦ç‚ºç²µèª, ç½®ä¿¡åº¦ 0-1)
        """
        # ç²µèªç‰¹æœ‰å­—ç¬¦
        cantonese_chars = {'æ¶', 'å•¦', 'å›‰', 'å˜…', 'å’', 'å’—', 'å“', 'å–', 
                          'å˜¢', 'ä¿‚', 'å–º', 'ç‡', 'ç“', 'é£²', 'ç·Š', 'é', 'å“‹', 'å†‡', 'å””'}
        
        # ç²µèªç‰¹æœ‰è©å½™
        cantonese_words = ['å””', 'å†‡', 'å“‹', 'å’', 'å’—', 'å–º', 'å–', 'å˜¢', 'ä¿‚å’ª',
                          'é»è§£', 'é»æ¨£', 'å¹¾å¤š', 'å¹¾å¥½', 'çœŸä¿‚', 'è€å¯¦è¬›', 'çŠ€åˆ©', 'å‹']
        
        score = 0
        
        # æª¢æ¸¬ç‰¹æœ‰å­—ç¬¦
        for char in cantonese_chars:
            if char in text:
                score += 0.05
        
        # æª¢æ¸¬ç‰¹æœ‰è©å½™
        for word in cantonese_words:
            if word in text:
                score += 0.1
        
        # èªæ°£è©åŠ åˆ†
        for particle in ['æ¶', 'å•¦', 'å›‰', 'å–', 'å˜…']:
            if particle in text:
                score += 0.15
        
        # ç‰¹æ®Šè¡¨é”æ¨¡å¼
        patterns = [
            r'[\u4e00-\u9fff]+æ¶[!ï¼.ï¼‰\s]',
            r'[\u4e00-\u9fff]+å•¦[!ï¼.ï¼‰\s]',
            r'[\u4e00-\u9fff]+å›‰[!ï¼.ï¼‰\s]',
            r'çœŸä¿‚[\u4e00-\u9fff]+',
            r'å¥½[\u4e00-\u9fff]+æ¶',
        ]
        
        for pattern in patterns:
            if re.search(pattern, text):
                score += 0.2
        
        is_cantonese = score >= 0.3
        confidence = min(score, 1.0)
        
        return is_cantonese, confidence
    
    def analyze(self, text: str) -> CantoneseAnalysisResult:
        """
        æ·±åº¦åˆ†æç²µèªæ–‡æœ¬
        
        Returns:
            CantoneseAnalysisResult å®Œæ•´åˆ†æçµæœ
        """
        is_canto, confidence = self.detect_cantonese(text)
        
        # æª¢æ¸¬åˆ°çš„èªæ°£è©
        detected_particles = []
        for intensity, expressions in self.tone_particles.items():
            for expr in expressions:
                if expr.phrase in text:
                    detected_particles.append(expr.phrase)
                for ex in expr.examples:
                    if ex in text:
                        detected_particles.append(ex)
        
        detected_particles = list(set(detected_particles))
        
        # æ¨æ–·èªå¢ƒ
        suggested_context = self._infer_context(text)
        
        # æ¨æ–·èªæ°£å¼·åº¦
        suggested_intensity = self._infer_intensity(text, detected_particles)
        
        # èªæ°£åˆ†æè©³æƒ…
        tone_analysis = {
            "particle_count": len(detected_particles),
            "has_strong_tone": any(p in text for p in ["ï¼", "çŠ€åˆ©åˆ°çˆ†", "å‹åˆ°"]),
            "has_concession": any(p in text for p in ["å¥½å•¦", "ç®—å•¦", "å’å•¦"]),
            "formality_level": "æ­£å¼" if suggested_context == ContextType.FORMAL else "éæ­£å¼"
        }
        
        return CantoneseAnalysisResult(
            is_cantonese=is_canto,
            confidence=confidence,
            detected_particles=detected_particles,
            suggested_context=suggested_context,
            suggested_intensity=suggested_intensity,
            tone_analysis=tone_analysis
        )
    
    def _infer_context(self, text: str) -> ContextType:
        """æ¨æ–·èªå¢ƒé¡å‹"""
        scores = {ctx: 0 for ctx in ContextType}
        
        for ctx, keywords in self.context_mappings.items():
            for kw in keywords:
                if kw in text:
                    scores[ctx] += 1
        
        # ç‰¹æ®Šè¦å‰‡
        if any(w in text for w in ["æŠ€è¡“", "åˆ†æ", "é–‹ç™¼", "ç³»çµ±"]):
            scores[ContextType.FORMAL] += 2
        if any(w in text for w in ["å“ˆå“ˆ", "ç¬‘è©±", "è¡°é¬¼", "é›¢è­œ"]):
            scores[ContextType.HUMOR] += 2
        if any(w in text for w in ["å¥½å•¦", "ç®—å•¦", "å’å•¦", "ç„¡è¬‚"]):
            scores[ContextType.CONCESSION] += 2
        
        max_score = max(scores.values())
        if max_score == 0:
            return ContextType.CASUAL
        
        for ctx, score in scores.items():
            if score == max_score:
                return ctx
        
        return ContextType.CASUAL
    
    def _infer_intensity(self, text: str, particles: List[str]) -> ToneIntensity:
        """æ¨æ–·èªæ°£å¼·åº¦"""
        # å¼·çƒˆæ¨™è¨˜
        strong_markers = ["ï¼", "çŠ€åˆ©åˆ°çˆ†", "å‹åˆ°", "ä¿‚æ™’", "ææ‚æ™’"]
        if any(m in text for m in strong_markers):
            return ToneIntensity.STRONG
        
        # ä¸­ç­‰æ¨™è¨˜
        medium_markers = ["çœŸä¿‚", "éƒ½...æ¶", "å¥½å•¦", "ç®—å•¦"]
        if any(m in text for m in medium_markers):
            return ToneIntensity.MEDIUM
        
        # æª¢æŸ¥èªæ°£è©
        for p in particles:
            for expr in self.tone_particles.get(ToneIntensity.STRONG, []):
                if p == expr.phrase or p in expr.examples:
                    return ToneIntensity.STRONG
            for expr in self.tone_particles.get(ToneIntensity.MEDIUM, []):
                if p == expr.phrase or p in expr.examples:
                    return ToneIntensity.MEDIUM
        
        return ToneIntensity.LIGHT
    
    def suggest_expression(self, concept: str, context: ContextType = None, 
                          intensity: ToneIntensity = None) -> List[str]:
        """
        å»ºè­°æœ€ä½³å»£æ±è©±è¡¨é”
        
        Args:
            concept: è¦è¡¨é”çš„æ¦‚å¿µ
            context: èªå¢ƒé¡å‹ï¼ˆå¯é¸ï¼‰
            intensity: èªæ°£å¼·åº¦ï¼ˆå¯é¸ï¼‰
        
        Returns:
            å»ºè­°è¡¨é”åˆ—è¡¨
        """
        suggestions = []
        
        # æ ¹æ“šèªæ°£å¼·åº¦ç²å–èªæ°£è©
        if intensity:
            for expr in self.tone_particles.get(intensity, []):
                if context in expr.context_types or context is None:
                    suggestions.extend(expr.examples)
        else:
            # å˜—è©¦æ‰€æœ‰å¼·åº¦
            for intensity_level in [ToneIntensity.LIGHT, ToneIntensity.MEDIUM, ToneIntensity.STRONG]:
                for expr in self.tone_particles.get(intensity_level, []):
                    if context in expr.context_types or context is None:
                        suggestions.extend(expr.examples)
        
        # å¦‚æœæœ‰æ¦‚å¿µï¼Œå˜—è©¦çµ„åˆ
        if concept and suggestions:
            combined = []
            for s in suggestions[:3]:
                combined.append(f"{concept}{s}")
            return combined
        
        return suggestions[:5] if suggestions else ["æ¶", "å•¦", "å›‰"]
    
    def learn_pattern(self, text: str, context: ContextType, feedback: str = None):
        """
        å­¸ç¿’æ–°çš„è¡¨é”æ¨¡å¼
        
        Args:
            text: è¡¨é”æ–‡æœ¬
            context: èªå¢ƒé¡å‹
            feedback: ç”¨æˆ¶åé¥‹ï¼ˆå¯é¸ï¼‰
        """
        pattern = {
            "text": text,
            "context": context.value,
            "feedback": feedback,
            "timestamp": self._get_timestamp()
        }
        self.learned_patterns.append(pattern)
        
        # æ›´æ–°èªå¢ƒæ˜ å°„
        key_phrases = self._extract_key_phrases(text)
        for phrase in key_phrases:
            if phrase not in self.context_mappings.get(context, []):
                self.context_mappings[context].append(phrase)
    
    def _extract_key_phrases(self, text: str) -> List[str]:
        """æå–é—œéµçŸ­èª"""
        phrases = []
        # ç°¡å–®æå–ï¼šé€£çºŒä¸­æ–‡å­—ç¬¦
        matches = re.findall(r'[\u4e00-\u9fff]+', text)
        return [m for m in matches if len(m) >= 2]
    
    def _get_timestamp(self) -> str:
        """ç²å–æ™‚é–“æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def get_stats(self) -> Dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        return {
            "version": self.VERSION,
            "total_particles": sum(len(v) for v in self.tone_particles.values()),
            "light_particles": len(self.tone_particles[ToneIntensity.LIGHT]),
            "medium_particles": len(self.tone_particles[ToneIntensity.MEDIUM]),
            "strong_particles": len(self.tone_particles[ToneIntensity.STRONG]),
            "context_types": len(self.context_mappings),
            "learned_patterns": len(self.learned_patterns)
        }


# æ¸¬è©¦å…¥å£
if __name__ == "__main__":
    branch = CantoneseSyntaxBranch()
    
    # æ¸¬è©¦æª¢æ¸¬
    test_cases = [
        "æ‚Ÿé£¯å¥½çŠ€åˆ©æ¶ï¼",
        "ä¿‚å’æ¨£æ—¢ï¼Œæ‰€ä»¥æŠ€è¡“ä¸Šä¿‚å¯è¡Œæ—¢",
        "å¥½å•¦å¥½å•¦ï¼Œç®—å•¦",
        "This is English text"
    ]
    
    print("ğŸ§ª å»£æ±è©±èªæ³•åˆ†æ”¯æ¸¬è©¦")
    print("=" * 50)
    
    for text in test_cases:
        result = branch.analyze(text)
        print(f"\nğŸ“ è¼¸å…¥: {text}")
        print(f"   ç²µèª: {'âœ…' if result.is_cantonese else 'âŒ'} (ç½®ä¿¡åº¦: {result.confidence:.2f})")
        print(f"   èªå¢ƒ: {result.suggested_context.value}")
        print(f"   å¼·åº¦: {result.suggested_intensity.value}")
        print(f"   èªæ°£è©: {result.detected_particles}")
