# Reference: 08 - Advanced AI Collaboration (2026 Edition)

Working with an AI pair programmer requires a different style of communication than working with a human. This guide provides advanced patterns for maximizing the effectiveness of AI-assisted development, based on 2026 best practices [1].

## 1. The "Big Daddy" Rule: Elevate the AI's Role

At the beginning of a development session, set the AI's role to be more than just a coderâ€”make it an architect and a critic.

**Good Prompt:**
> "You are my expert AI pair programmer, acting as a principal engineer. We are building a production-grade application. I expect you to think critically, identify potential issues, challenge my assumptions, suggest better architectural patterns, and ask clarifying questions *before* you write code."

## 2. Multi-Model Strategy: "Model Musical Chairs"

Different models excel at different tasks. Do not use a single model for everything. A state-of-the-art workflow involves using a portfolio of models:

| Task | Recommended Model Type | Example |
| :--- | :--- | :--- |
| **Planning & Reasoning** | High-reasoning, large context window | `gpt-4.1-mini`, `gemini-2.5-flash` |
| **Code Generation** | Fast, code-optimized | `gpt-4.1-nano` |
| **Code Review & Analysis** | High-accuracy, large context window | `gemini-2.5-flash` |
| **Documentation** | Creative, fluent language | `gpt-4.1-mini` |

## 3. Context Packing: Give the AI Perfect Memory

The AI's output is only as good as its input. Provide it with all the necessary context using automated tools.

- **Use Context Management Tools**: Use tools like **gitingest**, **repo2txt**, or **Context7 MCP** to automatically package the relevant parts of your codebase into the prompt.
- **Reference the Spec**: Always anchor your requests to the `spec.md` and `PLAN.md`.

**Good Prompt:**
> "I need to implement Task #5 from `PLAN.md` ('Create user registration endpoint'). Here are the relevant files: `spec.md`, `PLAN.md`, `references/04-security.md`, and the failing test `tests/integration/auth.test.ts`. Please generate the code to make the test pass."

## 4. The "Quality Gate" Prompt

After the AI generates a block of code, force it to self-correct by using a "Quality Gate" prompt.

**Good Prompt:**
> "Stop. Before I use this code, please review it against our development standards. Specifically, check for the following:
> 1.  **Security**: Does this align with our `references/04-security.md` (OWASP 2025)?
> 2.  **Error Handling**: Are all fallible operations handled according to `references/07-error-handling.md`?
> 3.  **Testing**: Does this change require a new unit test?
>
Please provide the corrected code if you find any issues."

## 5. The "Reverse Question" Technique

Challenge the AI to think more deeply about the code it has written.

**Good Prompts:**
- `"What are the three biggest risks with the code you just wrote? How can we mitigate them?"`
- `"Imagine this code needs to handle 1000 requests per second. What would be the performance bottleneck?"`
- `"What is one alternative approach to solving this problem, and what are its pros and cons compared to your solution?"`

---

### References

[1] Osmani, A. (2025, December 19). *My LLM coding workflow going into 2026*. Medium.
